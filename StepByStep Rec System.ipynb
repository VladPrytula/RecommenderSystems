{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('export_2017.csv', encoding = \"utf-8\")#, nrows = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCM_N_ORDER_POS_NR</th>\n",
       "      <th>SCM_N_ORDER_NR</th>\n",
       "      <th>SCM_N_ORDER_NR_NC</th>\n",
       "      <th>TDT_T_KEY_ORDER_DATE</th>\n",
       "      <th>ART_N_KEY_ARTICLE</th>\n",
       "      <th>PPR_N_KEY_PHYS_PRODUCT</th>\n",
       "      <th>CUS_N_KEY_CUSTOMER</th>\n",
       "      <th>SCM_D_QUANTITY</th>\n",
       "      <th>PPR_N_PHY_ARTICLE_ID</th>\n",
       "      <th>PPR_N_PHY_PRODUCT_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>ART_C_PROD_NUMBER</th>\n",
       "      <th>ART_V_ART_DESCRIPTION</th>\n",
       "      <th>ART_V_ART_DESCRIPTION_1</th>\n",
       "      <th>ART_V_PG_LEVEL3_DESC</th>\n",
       "      <th>ART_V_PG_LEVEL4_DESC</th>\n",
       "      <th>ART_V_PG_LEVEL5_DESC</th>\n",
       "      <th>ART_V_PG_LEVEL6_DESC</th>\n",
       "      <th>ART_V_MANUFACTURER_DESC</th>\n",
       "      <th>PPR_ART_CLASS_DESC</th>\n",
       "      <th>PPR_N_LEVEL2_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>341999621</td>\n",
       "      <td>80391417</td>\n",
       "      <td>0</td>\n",
       "      <td>06-JAN-17</td>\n",
       "      <td>1311010</td>\n",
       "      <td>62776372</td>\n",
       "      <td>12378259</td>\n",
       "      <td>1.00</td>\n",
       "      <td>61312</td>\n",
       "      <td>19997</td>\n",
       "      <td>...</td>\n",
       "      <td>139428</td>\n",
       "      <td>139428.16 Royal Canin British Shorthair Adult ...</td>\n",
       "      <td>139428.16 Royal Canin British Shorthair Adult ...</td>\n",
       "      <td>Katzenfutter trocken</td>\n",
       "      <td>Royal Canin Rasse (Breed)</td>\n",
       "      <td>British Shorthair</td>\n",
       "      <td>British Shorthair</td>\n",
       "      <td>Royal Canin</td>\n",
       "      <td>Royal Canin</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348334117</td>\n",
       "      <td>81849313</td>\n",
       "      <td>0</td>\n",
       "      <td>02-FEB-17</td>\n",
       "      <td>2031175</td>\n",
       "      <td>111951408</td>\n",
       "      <td>2913095</td>\n",
       "      <td>1.00</td>\n",
       "      <td>70828</td>\n",
       "      <td>48693</td>\n",
       "      <td>...</td>\n",
       "      <td>523432</td>\n",
       "      <td>523432.4 Bozita Original - 12 kg + 1,8 kg gratis</td>\n",
       "      <td>523432.4 Bozita Original - 12 kg + 1,8 kg gratis</td>\n",
       "      <td>Hundefutter trocken</td>\n",
       "      <td>Bozita</td>\n",
       "      <td>Bozita</td>\n",
       "      <td>Bozita</td>\n",
       "      <td>Doggy-Bozita</td>\n",
       "      <td>Dry Food Cat / Dog</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348334114</td>\n",
       "      <td>81849313</td>\n",
       "      <td>0</td>\n",
       "      <td>02-FEB-17</td>\n",
       "      <td>1568093</td>\n",
       "      <td>53626549</td>\n",
       "      <td>2913095</td>\n",
       "      <td>1.00</td>\n",
       "      <td>56851</td>\n",
       "      <td>43068</td>\n",
       "      <td>...</td>\n",
       "      <td>468126</td>\n",
       "      <td>468126.4 Sparpaket Lukullus feine Kauknochen 3...</td>\n",
       "      <td>468126.4 Sparpaket Lukullus feine Kauknochen 3...</td>\n",
       "      <td>Hundesnacks</td>\n",
       "      <td>★ Lukullus</td>\n",
       "      <td>Lukullus feine Kauknochen</td>\n",
       "      <td>Lukullus feine Kauknochen</td>\n",
       "      <td>MATINA</td>\n",
       "      <td>snacks</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>354903151</td>\n",
       "      <td>83341895</td>\n",
       "      <td>0</td>\n",
       "      <td>02-MAR-17</td>\n",
       "      <td>1910589</td>\n",
       "      <td>38614848</td>\n",
       "      <td>7097883</td>\n",
       "      <td>0.25</td>\n",
       "      <td>51010</td>\n",
       "      <td>39043</td>\n",
       "      <td>...</td>\n",
       "      <td>445245</td>\n",
       "      <td>445245.29 Sparpaket Animonda Carny Adult 24 x ...</td>\n",
       "      <td>445245.29 Sparpaket Animonda Carny Adult 24 x ...</td>\n",
       "      <td>Katzenfutter nass</td>\n",
       "      <td>Animonda Carny</td>\n",
       "      <td>Carny Fleisch</td>\n",
       "      <td>Carny Fleisch</td>\n",
       "      <td>Animonda</td>\n",
       "      <td>Canned Food Cat / Dog</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>354903151</td>\n",
       "      <td>83341895</td>\n",
       "      <td>0</td>\n",
       "      <td>02-MAR-17</td>\n",
       "      <td>1910589</td>\n",
       "      <td>38614828</td>\n",
       "      <td>7097883</td>\n",
       "      <td>0.25</td>\n",
       "      <td>51174</td>\n",
       "      <td>39043</td>\n",
       "      <td>...</td>\n",
       "      <td>445245</td>\n",
       "      <td>445245.29 Sparpaket Animonda Carny Adult 24 x ...</td>\n",
       "      <td>445245.29 Sparpaket Animonda Carny Adult 24 x ...</td>\n",
       "      <td>Katzenfutter nass</td>\n",
       "      <td>Animonda Carny</td>\n",
       "      <td>Carny Fleisch</td>\n",
       "      <td>Carny Fleisch</td>\n",
       "      <td>Animonda</td>\n",
       "      <td>Canned Food Cat / Dog</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SCM_N_ORDER_POS_NR  SCM_N_ORDER_NR  SCM_N_ORDER_NR_NC TDT_T_KEY_ORDER_DATE  \\\n",
       "0           341999621        80391417                  0            06-JAN-17   \n",
       "1           348334117        81849313                  0            02-FEB-17   \n",
       "2           348334114        81849313                  0            02-FEB-17   \n",
       "3           354903151        83341895                  0            02-MAR-17   \n",
       "4           354903151        83341895                  0            02-MAR-17   \n",
       "\n",
       "   ART_N_KEY_ARTICLE  PPR_N_KEY_PHYS_PRODUCT  CUS_N_KEY_CUSTOMER  \\\n",
       "0            1311010                62776372            12378259   \n",
       "1            2031175               111951408             2913095   \n",
       "2            1568093                53626549             2913095   \n",
       "3            1910589                38614848             7097883   \n",
       "4            1910589                38614828             7097883   \n",
       "\n",
       "   SCM_D_QUANTITY  PPR_N_PHY_ARTICLE_ID  PPR_N_PHY_PRODUCT_ID       ...        \\\n",
       "0            1.00                 61312                 19997       ...         \n",
       "1            1.00                 70828                 48693       ...         \n",
       "2            1.00                 56851                 43068       ...         \n",
       "3            0.25                 51010                 39043       ...         \n",
       "4            0.25                 51174                 39043       ...         \n",
       "\n",
       "   ART_C_PROD_NUMBER                              ART_V_ART_DESCRIPTION  \\\n",
       "0             139428  139428.16 Royal Canin British Shorthair Adult ...   \n",
       "1             523432   523432.4 Bozita Original - 12 kg + 1,8 kg gratis   \n",
       "2             468126  468126.4 Sparpaket Lukullus feine Kauknochen 3...   \n",
       "3             445245  445245.29 Sparpaket Animonda Carny Adult 24 x ...   \n",
       "4             445245  445245.29 Sparpaket Animonda Carny Adult 24 x ...   \n",
       "\n",
       "                             ART_V_ART_DESCRIPTION_1  ART_V_PG_LEVEL3_DESC  \\\n",
       "0  139428.16 Royal Canin British Shorthair Adult ...  Katzenfutter trocken   \n",
       "1   523432.4 Bozita Original - 12 kg + 1,8 kg gratis   Hundefutter trocken   \n",
       "2  468126.4 Sparpaket Lukullus feine Kauknochen 3...           Hundesnacks   \n",
       "3  445245.29 Sparpaket Animonda Carny Adult 24 x ...     Katzenfutter nass   \n",
       "4  445245.29 Sparpaket Animonda Carny Adult 24 x ...     Katzenfutter nass   \n",
       "\n",
       "        ART_V_PG_LEVEL4_DESC       ART_V_PG_LEVEL5_DESC  \\\n",
       "0  Royal Canin Rasse (Breed)          British Shorthair   \n",
       "1                     Bozita                     Bozita   \n",
       "2                 ★ Lukullus  Lukullus feine Kauknochen   \n",
       "3             Animonda Carny              Carny Fleisch   \n",
       "4             Animonda Carny              Carny Fleisch   \n",
       "\n",
       "        ART_V_PG_LEVEL6_DESC ART_V_MANUFACTURER_DESC     PPR_ART_CLASS_DESC  \\\n",
       "0          British Shorthair             Royal Canin            Royal Canin   \n",
       "1                     Bozita            Doggy-Bozita     Dry Food Cat / Dog   \n",
       "2  Lukullus feine Kauknochen                  MATINA                 snacks   \n",
       "3              Carny Fleisch                Animonda  Canned Food Cat / Dog   \n",
       "4              Carny Fleisch                Animonda  Canned Food Cat / Dog   \n",
       "\n",
       "  PPR_N_LEVEL2_ID  \n",
       "0               3  \n",
       "1               2  \n",
       "2               2  \n",
       "3               3  \n",
       "4               3  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23768830 entries, 0 to 23768829\n",
      "Data columns (total 22 columns):\n",
      "SCM_N_ORDER_POS_NR         int64\n",
      "SCM_N_ORDER_NR             int64\n",
      "SCM_N_ORDER_NR_NC          int64\n",
      "TDT_T_KEY_ORDER_DATE       object\n",
      "ART_N_KEY_ARTICLE          int64\n",
      "PPR_N_KEY_PHYS_PRODUCT     int64\n",
      "CUS_N_KEY_CUSTOMER         int64\n",
      "SCM_D_QUANTITY             float64\n",
      "PPR_N_PHY_ARTICLE_ID       int64\n",
      "PPR_N_PHY_PRODUCT_ID       int64\n",
      "ART_N_KEY_ARTICLE_1        int64\n",
      "ART_C_ART_NUMBER           float64\n",
      "ART_C_PROD_NUMBER          int64\n",
      "ART_V_ART_DESCRIPTION      object\n",
      "ART_V_ART_DESCRIPTION_1    object\n",
      "ART_V_PG_LEVEL3_DESC       object\n",
      "ART_V_PG_LEVEL4_DESC       object\n",
      "ART_V_PG_LEVEL5_DESC       object\n",
      "ART_V_PG_LEVEL6_DESC       object\n",
      "ART_V_MANUFACTURER_DESC    object\n",
      "PPR_ART_CLASS_DESC         object\n",
      "PPR_N_LEVEL2_ID            int64\n",
      "dtypes: float64(2), int64(11), object(9)\n",
      "memory usage: 3.9+ GB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## should we have any missing customer data\n",
    "cleaned_retail = raw_df.loc[pd.isnull(raw_df.CUS_N_KEY_CUSTOMER) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23768830 entries, 0 to 23768829\n",
      "Data columns (total 22 columns):\n",
      "SCM_N_ORDER_POS_NR         int64\n",
      "SCM_N_ORDER_NR             int64\n",
      "SCM_N_ORDER_NR_NC          int64\n",
      "TDT_T_KEY_ORDER_DATE       object\n",
      "ART_N_KEY_ARTICLE          int64\n",
      "PPR_N_KEY_PHYS_PRODUCT     int64\n",
      "CUS_N_KEY_CUSTOMER         int64\n",
      "SCM_D_QUANTITY             float64\n",
      "PPR_N_PHY_ARTICLE_ID       int64\n",
      "PPR_N_PHY_PRODUCT_ID       int64\n",
      "ART_N_KEY_ARTICLE_1        int64\n",
      "ART_C_ART_NUMBER           float64\n",
      "ART_C_PROD_NUMBER          int64\n",
      "ART_V_ART_DESCRIPTION      object\n",
      "ART_V_ART_DESCRIPTION_1    object\n",
      "ART_V_PG_LEVEL3_DESC       object\n",
      "ART_V_PG_LEVEL4_DESC       object\n",
      "ART_V_PG_LEVEL5_DESC       object\n",
      "ART_V_PG_LEVEL6_DESC       object\n",
      "ART_V_MANUFACTURER_DESC    object\n",
      "PPR_ART_CLASS_DESC         object\n",
      "PPR_N_LEVEL2_ID            int64\n",
      "dtypes: float64(2), int64(11), object(9)\n",
      "memory usage: 4.1+ GB\n"
     ]
    }
   ],
   "source": [
    "cleaned_retail.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we make any sort of ratings matrix, it would be nice to have a lookup table that keeps track of each item ID along with a description of that item. Let’s make that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lookup = cleaned_retail[['ART_C_PROD_NUMBER', 'ART_V_ART_DESCRIPTION']].drop_duplicates() # Only get unique item/description pairs\n",
    "item_lookup['ART_C_PROD_NUMBER'] = item_lookup.ART_C_PROD_NUMBER.astype(str) # Encode as strings for future lookup ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ART_C_PROD_NUMBER</th>\n",
       "      <th>ART_V_ART_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139428</td>\n",
       "      <td>139428.16 Royal Canin British Shorthair Adult ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>523432</td>\n",
       "      <td>523432.4 Bozita Original - 12 kg + 1,8 kg gratis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>468126</td>\n",
       "      <td>468126.4 Sparpaket Lukullus feine Kauknochen 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>445245</td>\n",
       "      <td>445245.29 Sparpaket Animonda Carny Adult 24 x ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>451643</td>\n",
       "      <td>451643.2 Felix Häppchen in Gelee oder Leckerbi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ART_C_PROD_NUMBER                              ART_V_ART_DESCRIPTION\n",
       "0            139428  139428.16 Royal Canin British Shorthair Adult ...\n",
       "1            523432   523432.4 Bozita Original - 12 kg + 1,8 kg gratis\n",
       "2            468126  468126.4 Sparpaket Lukullus feine Kauknochen 3...\n",
       "3            445245  445245.29 Sparpaket Animonda Carny Adult 24 x ...\n",
       "5            451643  451643.2 Felix Häppchen in Gelee oder Leckerbi..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_lookup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can tell us what each item is, such as that ART_C_PROD_NUMBER 3481 is a  Dog Design Decke Hundeschar . Now that this has been created, we need to:\n",
    "\n",
    "1. Group purchase quantities together by stock code and item ID\n",
    "2. Change any sums that equal zero to one (this can happen if items were returned, but we want to indicate that the user actually purchased the item instead of assuming no interaction between the user and the item ever took place)\n",
    "3. Only include customers with a positive purchase total to eliminate possible errors\n",
    "4. *Set up our sparse ratings matrix*\n",
    "\n",
    "This last step is especially important if you don’t want to have unnecessary memory issues! If you think about it, our matrix is going to contain thousands of items and thousands of users with a user/item value required for every possible combination. That is a LARGE matrix, so we can save a lot of memory by keeping the matrix sparse and only saving the locations and values of items that are not zero.\n",
    "\n",
    "The code below will finish the preprocessing steps necessary for our final ratings sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladyslavp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUS_N_KEY_CUSTOMER</th>\n",
       "      <th>ART_C_PROD_NUMBER</th>\n",
       "      <th>SCM_D_QUANTITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>52735</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>397041</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>447409</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>84</td>\n",
       "      <td>41989</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>84</td>\n",
       "      <td>160773</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CUS_N_KEY_CUSTOMER  ART_C_PROD_NUMBER  SCM_D_QUANTITY\n",
       "0                   22              52735             5.0\n",
       "7                   22             397041             4.0\n",
       "12                  22             447409             4.0\n",
       "50                  84              41989             9.0\n",
       "54                  84             160773             9.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_retail['CUS_N_KEY_CUSTOMER '] = cleaned_retail.CUS_N_KEY_CUSTOMER.astype(int) # Convert to int for customer ID\n",
    "cleaned_retail = cleaned_retail[['ART_C_PROD_NUMBER', 'SCM_D_QUANTITY', 'CUS_N_KEY_CUSTOMER']] # Get rid of unnecessary info\n",
    "grouped_cleaned = cleaned_retail.groupby(['CUS_N_KEY_CUSTOMER', 'ART_C_PROD_NUMBER']).sum().reset_index() # Group together\n",
    "grouped_cleaned.SCM_D_QUANTITY.loc[grouped_cleaned.SCM_D_QUANTITY == 0] = 1 # Replace a sum of zero purchases with a one to\n",
    "# indicate purchased\n",
    "grouped_purchased = grouped_cleaned.query('SCM_D_QUANTITY > 3') # Only get customers where purchase totals were positive\n",
    "\n",
    "## If we look at our final resulting matrix of grouped purchases, we see the following:\n",
    "\n",
    "grouped_purchased.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### should I kick out the items with quantity less than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladyslavp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  \"\"\"\n",
      "C:\\Users\\vladyslavp\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "customers = list(np.sort(grouped_purchased.CUS_N_KEY_CUSTOMER.unique())) # Get our unique customers\n",
    "products = list(grouped_purchased.ART_C_PROD_NUMBER.unique()) # Get our unique products that were purchased\n",
    "quantity = list(grouped_purchased.SCM_D_QUANTITY) # All of our purchases\n",
    "\n",
    "rows = grouped_purchased.CUS_N_KEY_CUSTOMER.astype('category', categories = customers).cat.codes \n",
    "# Get the associated row indices\n",
    "cols = grouped_purchased.ART_C_PROD_NUMBER.astype('category', categories = products).cat.codes \n",
    "# Get the associated column indices\n",
    "purchases_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customers), len(products)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<472403x6494 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1375001 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchases_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.9551793569873"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_size = purchases_sparse.shape[0]*purchases_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_purchases = len(purchases_sparse.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_purchases/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Training and Validation Set\n",
    "\n",
    "Typically in Machine Learning applications, we need to test whether the model we just trained is any good on new data it hasn’t yet seen before from the training phase. We do this by creating a test set completely separate from the training set. Usually this is fairly simple: just take a random sample of the training example rows in our feature matrix and separate it away from the training set. That normally looks like this:\n",
    "\n",
    "With collaborative filtering, that’s not going to work because you need all of the user/item interactions to find the proper matrix factorization. A better method is to hide a certain percentage of the user/item interactions from the model during the training phase chosen at random. Then, check during the test phase how many of the items that were recommended the user actually ended up purchasing in the end. Ideally, you would ultimately test your recommendations with some kind of A/B test or utilizing data from a time series where all data prior to a certain point in time is used for training while data after a certain period of time is used for testing.\n",
    "\n",
    "For this example, because the time period is only 8 months and because of the purchasing type (products), it is most likely products won’t be purchased again in a short time period anyway. This will be a better test. You can see an example here:\n",
    "\n",
    "pic\n",
    "\n",
    "Our test set is an exact copy of our original data. The training set, however, will mask a random percentage of user/item interactions and act as if the user never purchased the item (making it a sparse entry with a zero). We then check in the test set which items were recommended to the user that they ended up actually purchasing. If the users frequently ended up purchasing the items most recommended to them by the system, we can conclude the system seems to be working.\n",
    "\n",
    "As an additional check, we can compare our system to simply recommending the most popular items to every user (beating popularity is a bit difficult). This will be our baseline.\n",
    "\n",
    "This method of testing isn’t necessarily the “correct” answer, because it depends on how you want to use the recommender system. However, it is a practical way of testing performance I will use for this example.\n",
    "\n",
    "Now that we have a plan on how to separate our training and testing sets, let’s create a function that can do this for us. We will also import the random library and set a seed so that you will see the same results as I did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(ratings, pct_test = 0.2):\n",
    "    '''\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "    compares with the actual interactions.\n",
    "    \n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    '''\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n",
    "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "    item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return our training set, a test set that has been binarized to 0/1 for purchased/not purchased, and a list of which users had at least one item masked. We will test the performance of the recommender system on these users only. I am masking 20% of the user/item interactions for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_train, product_test, product_users_altered = make_train(purchases_sparse, pct_test = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLOW Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeding Up ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This method is deprecated. Please use the AlternatingLeastSquares class instead\n",
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n",
      "100%|██████████| 50.0/50 [00:24<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "alpha = 15\n",
    "user_vecs, item_vecs = implicit.alternating_least_squares((product_train*alpha).astype('double'), \n",
    "                                                          factors=20, \n",
    "                                                          regularization = 0.1, \n",
    "                                                         iterations = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(predictions, test):\n",
    "    '''\n",
    "    This simple function will output the area under the curve using sklearn's metrics. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    - predictions: your prediction output\n",
    "    \n",
    "    - test: the actual target result you are comparing to\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - AUC (area under the Receiver Operating Characterisic curve)\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, utilize this helper function inside of a second function that will calculate the AUC for each user in our training set that had at least one item masked. It should also calculate AUC for the most popular items for our users to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model \n",
    "    \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
    "    \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "    \n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "    \n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    item_vecs = predictions[1]\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "    # End users iteration\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this function to see how our recommender system is doing. To use this function, we will need to transform our output from the ALS function to csr_matrix format and transpose the item vectors. The original pure Python version output the user and item vectors into the correct format already.\n",
    "\n",
    "calc_mean_auc(product_train, product_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mean_auc(product_train, product_users_altered, \n",
    "              [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)\n",
    "# AUC for our recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
